{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPAdZUuMZMh1DOmez114pZ+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/potuu/BreastCancerPredictionFromTissue/blob/main/BreastCancerFromTissue.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kaggle datasets download -d farhanmonsur/breast-cancer-split-dataset"
      ],
      "metadata": {
        "id": "YnTTn-j-w7Xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "h-8exktzu3gD"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "W-HDbxXKxk4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d farhanmonsur/breast-cancer-split-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4dFb3fQxUZC",
        "outputId": "953da186-59d2-471f-dc95-0669860ab7f7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Dataset URL: https://www.kaggle.com/datasets/farhanmonsur/breast-cancer-split-dataset\n",
            "License(s): unknown\n",
            "Downloading breast-cancer-split-dataset.zip to /content\n",
            " 99% 1.54G/1.55G [00:22<00:00, 94.1MB/s]\n",
            "100% 1.55G/1.55G [00:22<00:00, 75.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "AWYyF5z7xjQD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/breast-cancer-split-dataset.zip', 'r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "rVNOzJY-xj4K"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "eWBZ8rYOx9hL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
      ],
      "metadata": {
        "id": "lr20KI0ix-OB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3zrtDgrsx-94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extract_dir='/content/All Data Split'\n",
        "train_dir=os.path.join(extract_dir,'/content/All Data Split/Train')\n",
        "test_dir=os.path.join(extract_dir,'/content/All Data Split/Train')"
      ],
      "metadata": {
        "id": "-4Kid1TZx_Fa"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZJPKGgbax_L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    # rescale=1./255,         # Görüntüyü yeniden ölçeklendirir(daha küçük ölçekli verilerle çalışmak daha etkilidir)\n",
        "    # rotation_range=45,      # Görüntüleri rastgele olarak 0-45 derece aralığında döndürür.(model farklı açılarda görüntülerle karşılaştığında da doğru tahmin yapma yüzdesini artırır)\n",
        "    #width_shift_range=0.2,   # Görüntüyü yatay olarak ½20 orannında rastgele kaydırır.(nesnelerin görüntüde farklı yerlerde bulunmasına karşı dayanıklılığı sağlar)\n",
        "    #height_shift_range=0.2,  # Görüntüyü dikey olarak ½20 oranında rastgele kaydırır.(model, dikey kaymalara karşı dayanıklılık geliştirir)\n",
        "    shear_range=0.2,          # Görüntüyü kayma işlemine tabi tutar, kayma işlemi, görüntünün bir eksen boyunca eğilmesini sağlar.\n",
        "    #zoom_range=0.2,          # Görütüyü rastgele olarak ½20 oranında yakınlaştırır veya uzaklaştırır\n",
        "    horizontal_flip=True,     # Görüntüyü rasgele olarak yatay çevirir. Simetrik görüntülerin tanınma yeteneğini artırır\n",
        "    #fill_mode='nearest'      # Döndürme ya da kaydırma gibi dönüşümler sonucu oluşan boş alanları en yakın piksel renkleri ile doldurur\n",
        ")\n",
        "\n",
        "# Test verilerini yeniden ölçeklendirilmesi\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "2-Ycxv3gx_Ra"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "eğitim verilerinin yüklenmesi"
      ],
      "metadata": {
        "id": "FV6NLTWVx_W-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# yukarıda tanımladığımız train_datagen() nesnesini alıyoruz, ImageDataGenerator'un bir sınıfı olan flow_from_directory() fonksiyonu ile belirli bir önişlemeye tabi tutuyoruz.\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150, 150), # 150*150 piksellik olarak yeniden boyutlandırıyoruz\n",
        "    batch_size=32,          # Her seferinde 32'lik gruplar olacak şekilde yüklüyoruz. Ram kullanımında verimlilik sağlar.\n",
        "    class_mode='binary'     # Sınıflandırmanı iki olduğunu modele belirtiyoruz, sonuç olarak sadece 0 ve 1 durumları vardır. Örnek olarak cevap, ya siyahtır ya da beyazdır.\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbZiw0Wex_jO",
        "outputId": "1cce666b-c863-4e4a-a4e9-eb6f0d4b9a4a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 212421 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**test verilerinin yüklenmesi**"
      ],
      "metadata": {
        "id": "Bdl_YaWix_pq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator=test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(150,150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pEKp4Jmx_u7",
        "outputId": "18ab886f-8be7-49bc-d3eb-b72aa8853afc"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 212421 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CNN modelinin oluşturulması**\n",
        "\n",
        "---\n",
        "Görüntüyü alıp, işleyerek ikili sınıflandırma için bir tahmin yapar. CNN ile görüntüden özellikler çıkarır ve bunları kullanarak ikili sınıflandırma yapar.\n"
      ],
      "metadata": {
        "id": "9fSRmwOGx_2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Keras\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    # 150*150 boyutunda bir veriyi alır, relu ile negatif değerleri sıfırlayıp pozitif değerleri olduğu gibi geçirir(Doğrusal olmayan ilişkiyi sağlar) 32 kernel(filtre) uygular ve (3,3) boyutunda bir veridir.\n",
        "    MaxPooling2D(2, 2),\n",
        "    # Max-pooling, 2*2 alandaki en yüksek değeri seçerek görüntü boyutunu yarıya indirir.(Hesaplama maaliyetini düşürür ve önemli özellikleri korur)\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    # İkinci evrişim katmanı, önceki ile aynı mantıkla çalışır ancak 64 filtre kullanarak daha fazla özellik çıkarımı sağlar.\n",
        "    MaxPooling2D(2, 2),\n",
        "    # İkinci max-pooling katmanı, boyutu tekrar yarıya indirir.\n",
        "    Flatten(),\n",
        "    # Çok boyutlu çıktıları tek boyutlu bir vektöre dönüştürür(Böylece veriler, tam bağlantılı katmana(dense layer) beslenebilir)\n",
        "    Dense(128, activation='relu'),\n",
        "    # Tam bağlantılı katman, 128 nöronlu bir katmandır.\n",
        "    Dropout(0.5),\n",
        "    # Overfitting(aşırı öğrenme) sorununu azaltmak için rasgele olarak nöronları ½50 oranında devre dışı bırakır.\n",
        "    Dense(1, activation='sigmoid')\n",
        "    # Çıkış katmanıdır, yalnızca 1 nörona sahiptir(şu anki beynim gibi) sigmoid aktivasyonu funksiyonunu kullanır.(Sigmoid fonksiyonu, çıktıyı 0 ile 1 arasında bir değere sıkıştırır, bu da ikili sınıflandırma için kullanılır)\n",
        "])"
      ],
      "metadata": {
        "id": "3TsBYefkx_7a"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compile**"
      ],
      "metadata": {
        "id": "6eeboAcmyAJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Adaptive Moment Estimation algoritması, even I can't understand actually lol\n",
        "# binary_crossentropy modelin tahmin ettiği çıktı ile gerçek çıktı arasındaki farkı ölçer\n",
        "# accuracy ise modelin doğruluğunu ölçer"
      ],
      "metadata": {
        "id": "ol1m0UMLyAPL"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Modelin eğitilmesi** **6 SAAT 17 DAKİKA SÜRDÜ**"
      ],
      "metadata": {
        "id": "MTTnwQAOyAYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    #eğitim verilerini sağlayan veri üreteçi olarak kullanılır\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    # .samples toplam eğitim örneği sayısını, .batch_size her adımda işlenecek örnek sayısını ifade eder\n",
        "    epochs=10,\n",
        "    # Tüm eğitim verilerinin üzerinden kaç kez geçileceğini belirliyoruz\n",
        "    validation_data=test_generator,\n",
        "    # Her epoch sonrasında test_generator(doğrulama verilerini sağlayan veri üreteci olarak kullanılır) verilerini kullanarak test edilmesini sağlar\n",
        "    validation_steps=test_generator.samples // test_generator.batch_size\n",
        "    # her epoc sonrasında kaç adım yapılacağını belirler. .samples toplam doğrulama örneği sayısını, .batch_size ise her adımda işlenecek örnek sayısını ifade eder\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ud1VZZc2yAbR",
        "outputId": "82e872c6-60d9-41b1-888b-a7cad2321d44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m5502/6638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m30:23\u001b[0m 2s/step - accuracy: 0.7179 - loss: 7.0914"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Eğitim ve doğrulama doğruluğu grafiği**"
      ],
      "metadata": {
        "id": "yVx-YPZY06Ur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(history.history['accuracy'], label='Eğitim Doğruluğu')\n",
        "plt.plot(history.history['val_accuracy'], label='Doğrulama Doğruluğu')\n",
        "plt.title('Eğitim ve Doğrulama Doğruluğu')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9TmGXgTk06cE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Eğitim ve doğrulama kaybı grafiği**"
      ],
      "metadata": {
        "id": "kl-AZca806ij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(history.history['loss'], label='Eğitim Kaybı')\n",
        "plt.plot(history.history['val_loss'], label='Doğrulama Kaybı')\n",
        "plt.title('Eğitim ve Doğrulama Kaybı')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mqLrzxZI06n7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Modelin tahmin yapması ve doğruluğunun hesaplanması**"
      ],
      "metadata": {
        "id": "deUG0lii06ui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred = model.predict(test_generator)\n",
        "# Eğitimde kullanılan test_generator ile model üzerinde tahminler yapar\n",
        "y_pred = np.where(Y_pred > 0.5, 1, 0)\n",
        "# koşul sağlanıyorsa 1, sağlanmıyorsa 0 olarak tanımla, gelen binary değeri predict olarak ata"
      ],
      "metadata": {
        "id": "TeqF1KHL060L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Confusion Matrix Report**"
      ],
      "metadata": {
        "id": "8gt6kHYp0650"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Confussion Matrix')\n",
        "print(confusion_matrix(test_generator.classes, y_pred))\n",
        "# Tahmin sonuçlarının gerçek etiketleriyle karşılaştırarak bir confusion matris hesaplayıp, yazdırıyoruz"
      ],
      "metadata": {
        "id": "SXBgb4BC06-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classification Report**"
      ],
      "metadata": {
        "id": "xRHLl_eP10q0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Classification Report')\n",
        "target_names = ['Benign', 'Malignant']\n",
        "print(classification_report(test_generator.classes, y_pred, target_names=target_names))\n",
        "# Tahmin performanslarını özetlemek için sınıflandırma raporu üretip çıktısını yazıyoruz"
      ],
      "metadata": {
        "id": "GvJB4RW510wP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Doğruluk oranı (accuracy) hesaplama**"
      ],
      "metadata": {
        "id": "8aSbuISY101R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy=accuracy_score(test_generator.classes, y_pred)\n",
        "print(f\"Modelin doğruluk oranı: ½{accuracy *100:.2f}\")\n",
        "# Ne kadar doğru tahminler yaptığımızı anlamamıza imkan sağlar, genel başarıyı değerlendirmek için kullanılır"
      ],
      "metadata": {
        "id": "dKL0haqI1056"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**görüntülerin bölünmesi ve analiz edilmesi**"
      ],
      "metadata": {
        "id": "rm0YRg3G10_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from keras.preprocessing.image import load_img,img_to_array"
      ],
      "metadata": {
        "id": "H17spau011Dj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "tahmin sırasında görüntülerin bölünmesi ve analiz edilmesi"
      ],
      "metadata": {
        "id": "ldiOj3Zo2aBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random img_path=os.path.join(test_dir,'1', random.choice(os.path.join(test_dir,'1')))\n",
        "# rastgele bir görüntü yolu seç\n",
        "\n",
        "\n",
        "def predict_image_with_augmentation(image_path):\n",
        "    # Görüntüyü ekle ve ön işlemleri yap\n",
        "    img=load_img(image_path,target_size=(150,150))\n",
        "    img=img_to_array(img) / 255.0\n",
        "    img=np.expand_dims(img, axis=0)\n",
        "\n",
        "    # Augmentation işlemleri\n",
        "    img_gen=test_datagen.flow(img,batch_size=1)\n",
        "\n",
        "    for i in range(5):\n",
        "      aug_img=next(img_gen)[0]\n",
        "      plt.imshow(aug_img)\n",
        "      plt.axis('off')\n",
        "      plt.show()\n",
        "\n",
        "      # Tahmin yap\n",
        "      pred=model.predict(np.expand_dims(aug_img,axis=0))\n",
        "      if pred>=0.5:\n",
        "        print(f\"Model Tahmini: Kanserli(Confidence: {pred[0][0]:.2f})\")\n",
        "      else:\n",
        "        print(f\"Model Tahmini: Kansersiz(Confidence: {1-pred[0][0]:.2f})\")\n"
      ],
      "metadata": {
        "id": "jrsGTgl_4t6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "w7rus5xK2aNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict_image_with_augmentation(random_img_path)"
      ],
      "metadata": {
        "id": "RKFLREtD2aSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "IoImM8-b2aXR"
      }
    }
  ]
}